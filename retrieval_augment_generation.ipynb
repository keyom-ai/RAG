{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyML5/AppWhigpnc46OKEQ+0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keyom-ai/rag/blob/main/retrieval_augment_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This Notebook is created to solve RAG (retrieval augmented generation) use case - in this example we are feeding an external text file stored in a website.\n"
      ],
      "metadata": {
        "id": "6E0KNw_uVtfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of the code is installing required libraries:\n",
        "- [langchain](https://www.langchain.com/): mainly used for orchestration and chaining of prompts\n",
        "- [weaviate](https://weaviate.io/): open-source vector database\n",
        "- openai: no explanation needed :)\n",
        "- tiktoken: [tokenizer](https://github.com/openai/tiktoken) used by OpenAI cookbook\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8qOKPDMTV6Xh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVoDIGcQItRR"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai weaviate-client python-dotenv tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is setting up the environment variable OPENAI_API_KEY. Please make sure to replace `sk-abcdefghijklmnopqrstuvwxyz0123456789` with your own OpenAI API key. You can create an API key via their [API key page](https://platform.openai.com/api-keys).\n",
        "\n",
        "**A note: ** You may need to [add](https://platform.openai.com/account/billing/overview) $10 (minimum) in your API balance if you start getting capacity error or error code 401\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mNjGwd8AWetL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "OPENAI_API_KEY='sk-abcdefghijklmnopqrstuvwxyz0123456789'"
      ],
      "metadata": {
        "id": "0hHGkKy6IynF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
      ],
      "metadata": {
        "id": "Ut8nkaQ5JFcr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the code block which where we are retrieving the external data -- in this case it's **State Of The Union** we are going to use.\n",
        "\n",
        "Once retrieved from the URL, we are writing this as a file and loading it."
      ],
      "metadata": {
        "id": "fABuEL4gXjHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/modules/state_of_the_union.txt\"\n",
        "res = requests.get(url)\n",
        "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
        "    f.write(res.text)\n",
        "\n",
        "loader = TextLoader('./state_of_the_union.txt')\n",
        "documents = loader.load()\n"
      ],
      "metadata": {
        "id": "jsTQv3BhJIMX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step is mainly spillitng that file  into chunks so it can be fed to Embeddings model and then it can be stored in the vector database."
      ],
      "metadata": {
        "id": "ki4tSKfvX8N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(documents)\n"
      ],
      "metadata": {
        "id": "5W2VXphEJnl8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where we are telling langchain to use OpenAI Embeddings model and convert our text document into embeddings and store it into vector databse - in our case we are using **weaviate**\n",
        "\n",
        "There are many other Embeddings model exist, such as [Amazon Titan Embeddings](https://docs.aws.amazon.com/bedrock/latest/userguide/embeddings.html), [Cohere Embeddings](https://docs.cohere.com/docs/multilingual-language-models) and many more via [HuggingFace](https://huggingface.co/models?other=embeddings)\n",
        "\n",
        "**A note: ** You may need to [add](https://platform.openai.com/account/billing/overview) $10 (minimum) in your API balance if you start getting capacity error or error code 401 *italicized text*"
      ],
      "metadata": {
        "id": "YOYUtcz4YXpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Weaviate\n",
        "import weaviate\n",
        "from weaviate.embedded import EmbeddedOptions\n",
        "\n",
        "#OPENAI_API_KEY='sk-abcdefghijklmnopqrstuvwxyz0123456789'\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-abcdefghijklmnopqrstuvwxyz0123456789\"\n",
        "\n",
        "client = weaviate.Client(\n",
        "  embedded_options = EmbeddedOptions()\n",
        ")\n",
        "\n",
        "vectorstore = Weaviate.from_documents(\n",
        "    client = client,\n",
        "    documents = chunks,\n",
        "    embedding = OpenAIEmbeddings(),\n",
        "    by_text = False\n",
        ")\n"
      ],
      "metadata": {
        "id": "aJQDaHOHJqvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code block we are retrieving the information from the vector database."
      ],
      "metadata": {
        "id": "hsdJDIheY8Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "3XmAR8U4JtQJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code block we are getting the prompt ready for consumption."
      ],
      "metadata": {
        "id": "j--p95MBZGKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Use three sentences maximum and keep the answer concise.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "print(prompt)\n"
      ],
      "metadata": {
        "id": "rxQpBr2iMitV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is we are using the prompt and adding context via embedding store to reflect current information."
      ],
      "metadata": {
        "id": "Y152TdMeZPEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "query = \"What did the president say about Justice Breyer\"\n",
        "rag_chain.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "3-qu9mBCMleQ",
        "outputId": "a06f4e98-736e-4b33-ca1f-a319c77b4f41"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The president thanked Justice Breyer for his service and acknowledged his dedication to serving the country. The president also mentioned that he nominated Judge Ketanji Brown Jackson as a successor to continue Justice Breyer's legacy of excellence.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NrnSO2IIMoKo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}